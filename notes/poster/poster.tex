\documentclass{sciposter}
\usepackage{lipsum}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multicol}
\usepackage{subfig}
\usepackage{graphicx,url}
\usepackage[english]{babel}   
\usepackage[utf8]{inputenc}
%\usepackage{fancybullets}
\newtheorem{Def}{Definition}

% Poster size can be 36" wide by 44" tall (A0 paper size)

\title{{\fontsize{100}{120}\selectfont Real-Time Activity Classification by Matched Filtering Using Body-Worn Accelerometers}}

\author{Craig~Euler, C.T.~Lin, Bryan~Juarez, Melissa~Flores}

\institute 
{College of Engineering and Computer Science\\
California State University Northridge}

\email{craig.euler@gmail.com}

\begin{document}
\conference{{\bf IEEE 2016}, Anaheim CA December 19}

\maketitle

\begin{multicols}{3}

%%%%%%%%%%%%
% Abstract %
%%%%%%%%%%%%
\begin{abstract}
Having information of a user's activity can provide great use in modern-day devices such as ones that track and monitor the user's activity and fitness.
We demonstrate activity classification performance of the matched-filtering method with data obtained from a three-axis accelerometer worn by the user.
We also show the real-time processing capability of our algorithms on the MSP432P401R low-powered microcontroller.
Dimensionality reduction with principal component analysis (PCA) \cite{bishop_2006} is a data compression technique we use to improve our processing throughput which, inherently, has the added benefit of making     our data invariant to sensor orientation.
Data decimation in time is an additional throughput enhancement that we apply early to our data.
We make use of an instance-based learning algorithm to train the device to learn the individual's motion patterns and store that information as activity templates for use in our matched-filter.
\end{abstract}

%%%%%%%%%%%%%%%%
% Introduction %
%%%%%%%%%%%%%%%%
\section{Introduction}
We adopt the matched-filter method for classification to identify an individual's activity in real-time processing on a low-powered micro-controller.
Our algorithms are designed for computational efficiency to accommodate the resource limitations of a microcontroller.
Timing tests were performed on the MSP432 microcontroller.

Two main algorithms are described here: Activity classification for real-time processing and training to train the device to identify the user's activity for the purpose of real-time activity classification.

Because training module does not need to be performed in real time, this can be done on an external device such as a smart phone or tablet where processing resources are in greater abundance.
Training the module creates the reference signals to be used on the microcontroller for the real-time activity classification processing.

%%%%%%%%%%%%%%%
% Methodology %
%%%%%%%%%%%%%%%
\section{Methodology}
We use the matched-filter method for identifying a user's activity from data generated by body-worn accelerometers.
The matched-filter is based on the cross correlation of the data $\textbf{y} = \{y\}_{k=0}^{N-1}$ with the reference signal $\textbf{x} = \{x\}_{k=0}^{M-1}$.
The cross correlation of $\textbf{x}$ with $\textbf{y}$ is defined as:
%
\begin{equation} \label{eq:cross_correlation}
(\textbf{x} \star \textbf{y}) := \left \{\sum_{i=0}^{M-1}x_{i} y_{i+k} \right \}_{k=0}^{N-M-1}
\end{equation}
%
We can then normalize \eqref{eq:cross_correlation} by the following:
%
\begin{equation} \label{eq:norm_cross_correlation}
\widehat{(\textbf{x} \star \textbf{y})}_k := \frac{(\textbf{x} \star \textbf{y})_k}{||\textbf{x}|| \ || \widetilde{\textbf{y}}_k || }, \quad k = 0,1,...,N-M-1
\end{equation}
%
where $|| \cdot ||$ is the usual $\ell_2$ norm and $\widetilde{\textbf{y}}_k = \{y_p\}_{p=k}^{M+k-1}$.
\eqref{eq:norm_cross_correlation} is now bounded by $[-1,1]$.
We improve our computational efficiency from $\mathcal{O}(n^2)$ to $\mathcal{O}(n log_2n)$ by applying the convolution theorem to \eqref{eq:cross_correlation} and replacing it with:
%
\begin{equation} \label{eq:conv_theorem}
(\textbf{x} \star \textbf{y}) := FFT^{-1}(FFT(\textbf{x}') FFT(\textbf{y})^*)
\end{equation}
%
where $\textbf{x}'$ is $\textbf{x}$ that has been zero padded to the length of $\textbf{y}$ with the added restriction that the length of $\textbf{x}$ is no more than the length of $\textbf{y}$ and $FFT$ is the Fast Fourier Transform algorithm.
We are most interested where our reference $\textbf{x}$ best matches our data $\textbf{y}$.
We use the resulting max correlation as our metric for determining our matched-filter output as:
%
\begin{equation} \label{eq:matched_filter}
MF_{\textbf{x}}(\textbf{y}) := \underset{k \in [0, M-N)}{max} \left \{\widehat{(\textbf{x} \star \textbf{y})}_k \right \}
\end{equation}
%
If \eqref{eq:matched_filter} passes a set threshold, then the corresponding signal $\textbf{y}$ is classified as a match to the reference $\textbf{x}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Dimensionality Reduction %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dimensionality Reduction}
We manage to reduce our computational resources and remove our dependence on sensor orientation at the same time through a process of dimensionality reduction with principal component analysis (PCA) \cite{bishop_2006}.
We assume that over a short period of time, the user's limb movement is constrained mostly to two dimensions.
We project the acceleration data onto this plane and re-define our new axis accordingly.
If we let $\textbf{a} = \{a_i\}_{i=0}^{N}$ represent our demeaned acceleration data (with each $a_i$ being a column) over a specified time window in three dimensions, then the covariance matrix of our acceleration data is represented by the real-symmetric $3 \times 3$ matrix $Q = \textbf{a} \textbf{a}^T$.
The resulting unit length column eigenvectors of $Q$ are $V = (\textbf{v}^1,\textbf{v}^2,\textbf{v}^3)$ with their respective eigenvalues $\lambda^1 \geq \lambda^2 \geq \lambda^3$ of this matrix are orthonormal and point in the directions where the data varies most in descending order for each orthogonal direction.
Here, we use superscripts to identify the axis directions in ascending order to represent the primary, secondary, and tertiary principal axis directions respectively.
%
\begin{equation} \label{eq:project}
   \textbf{a}' := V^T \textbf{a}
\end{equation}
%
We now represent our acceleration data as $\textbf{a}'$ after projecting our acceleration data $\textbf{a}$ onto our rotated axis $V$ by \eqref{eq:project}.
We compute the matched-filter output by generalizing \eqref{eq:matched_filter} for two dimensions.
We augment our reference and signal with both dimensions appropriately for normalization and adding together the cross correlations as:
%
\begin{equation} \label{eq:cross_correlation_2}
\widehat{(\textbf{x}^{1,2} \star \textbf{y}^{1,2})}_k := \frac{(\textbf{x}^1 \star \textbf{y}^1)_k + (\textbf{x}^2 \star \textbf{y}^2)_k}{||[ \textbf{x}^1, \textbf{x}^2 ]|| \ || [ \widetilde{\textbf{y}}_k^1, \widetilde{\textbf{y}}_k^2 ] || },
\end{equation}
%
for $ k = 0,1,...,N-M-1 $. \\
%
\begin{equation} \label{eq:matched_filter_2}
MF_{\textbf{x}}^2(\textbf{y}) := \underset{k \in [0, M-N)}{max} \left \{\widehat{(\textbf{x}^{1,2} \star \textbf{y}^{1,2})}_k \right \}
\end{equation}
%
Here, the superscripts $1$ and $2$ represent the primary and secondary principal components of our data respectively.

%%%%%%%%%%%%%%
% Decimation %
%%%%%%%%%%%%%%
\section{Decimation}
Decimation is the first step applied to our data before any additional processing takes place.
Decimation is a process of reducing the sampling rate of the signal by filtering to mitigate any possible distortion effects due to aliasing followed by downsampling.
Decimation helps improve processing throughput.

For a decimation value of $D$, we define our triangle filter with the following weights:
%
\begin{equation} \label{eq:triangle_filter_weights}
w_k^D :=
\begin{cases}
  \frac{D+k}{D^2}, & \text{if }\ -D < k \leq 0 \\
  \frac{D-k}{D^2}, & \text{if } 0 < k < D \\
  0, & \text{otherwise}
\end{cases}
\end{equation}
%
and convolve it with our data to get
%
\begin{equation} \label{eq:convolve}
s'_k := \sum_{i=0}^{N} s_i w_{k-i}
\end{equation}
%
followed by a downsample
%
\begin{equation} \label{eq:downsample}
s''_k := s'_{(k+1)D-1}, \quad k = 0, 1, 2, ..., N/D.
\end{equation}

%%%%%%%%%%%%%%%%%%%%%
% Activity Training %
%%%%%%%%%%%%%%%%%%%%%
\section{Activity Training}
We are able to identify an individual's activity by matching the signal to a reference template.
We develop our reference for our matched-filter directly from a subset of the person's motion signature.
The individual performs a specified activity over a specified amount of time and we select the sub-interval of time that we find best represents the user's motion signature.
For a given activity, we attempt to find the representative signal $\textbf{s}$ of our individual's activity to be our template for our matched-filter.

If $\textbf{t} = \{t_k\}_{k=0}^{N_t}$ is our training set over $N_t$ data points, we define a collection of subsets $X$ of $\textbf{t}$:
%
\begin{equation} \label{eq:X_subsets_of_training_eq}
X := \left \{ \{t_k\}_{k=p}^{p+M-1} | p=mI \right \}
\end{equation}
%
and $Y$ of $\textbf{t}$:
%
\begin{equation} \label{eq:Y_subsets_of_training_eq}
Y := \left \{ \{t_k\}_{k=p}^{p+N-1} | p=nI \right \}
\end{equation}
%
where $M \leq N$, $I$ is a positive, fixed integer, and $(m,n) \in \mathbb{Z}^2$ where $(m,n)$ vary such that $0 \leq (m,n)I$ and $(m,n)I + (M,N) - 1 \leq N_t$. Then we can determine the representative signal $\textbf{s} \in X$ for our activity that satisfies the condition:
%
\begin{equation} \label{eq:s_condition}
\sum_{y \in Y}MF^2_{\textbf{s}}(\textbf{y}) \geq \sum_{y \in Y}MF^2_{\textbf{x}}(\textbf{y}), \quad \forall \textbf{x} \in X
\end{equation}

We chose this method for its simplicity and robustness against outliers in our training set. We anticipate that the user will have idle motion at the start and end of their training duration when they activate the training mode and with possible disruptions during the process.

%%%%%%%%%%%%%%%%%%%%%%%%%%
% Performance Assessment %
%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Performance Assessment}
The Kinetisense sensor was used for the algorithm performance assessment.
This unit has a three-axis accelerometer with an acceleration range of -5g to +5g and a sampling rate of 128Hz.
Samples of walking, jogging, and bicycling have been recorded with this unit attached to the ankle of the user.
A separate instance of walking data was used specifically for training the classifier.

\begin{figure}[!ht]
\centering
\subfigure[\label{fig:frac_walking_jogging} Jogging]{\includegraphics[width=0.45\textwidth]{fraction_threshold_walking_to_jogging.png}}
\subfigure[\label{fig:frac_walking_bicycling} Bicycling]{\includegraphics[width=0.45\textwidth]{fraction_threshold_walking_to_bicycling.png}}
\caption{Matched-filter performance comparing jogging and bicycling data against a reference for walking. Results produced at decimation 8.}
  \label{fig:MF_performance}
\end{figure}

Figures \ref{fig:frac_walking_jogging} and \ref{fig:frac_walking_bicycling} show the fraction of the correlation results that exceed the given correlation threshold when comparing the walking data reference to the given activity.

To assess the real-time processing potential of the algorithms outlined in this paper, a throughput assessment was performed on the MSP432P401R microcontroller with varying parameters.
The Texas Instruments - MSP432P401R is a low power plus performance microcontroller that is based on the ARM 32-Bit Cortex-M4F processor.
Some of the notable features of the MSP432P410R is having a clock frequency of 48 MHz, 64 kB SRAM, 256 kB Flash Memory, an IEEE 754-compliant single-precision Floating-Point Unit (FPU), and Memory Protection Unit (MPU).
The single-precision processing capability on this unit provides us with the dynamic range necessary to process the algorithms that fixed-point processing cannot provide.
The 64 kB of SRAM provides sufficient space to process our algorithms.
The 256 kB is more than enough flash memory to store the program and data references.

\begin{figure}[!ht]
\centering
\subfigure[\label{fig:multiple_comparison}]{\includegraphics[width=0.45\textwidth]{more_time_plots.png}}
\subfigure[\label{fig:timing_refs}]{\includegraphics[width=0.45\textwidth]{one_and_two_references.png}}
\caption{Timing results with varying sampling frequencies, time-window lengths, and number of references used for the matched-filter on the MSP432 microcontroller processor. The time window used for (b) is 4.0 seconds with timings measured at sampling frequencies of $16, 32, 62, 64, 75, 100,$ and $128$ Hz.}
\label{fig:timing}
\end{figure}
%
Figure \ref{fig:multiple_comparison} shows the execution time with varying time-window lengths and sampling frequencies while maintaining two references used in the matched-filter process while operating at decimation $2$.
Figure \ref{fig:timing_refs} shows the execution time over a $4.0$ second time window at decimation $8$ while varying the sampling frequency and number of references.

%%%%%%%%%%%%%%
% Conclusion %
%%%%%%%%%%%%%%
\section{Conclusion}
We have demonstrated excellent activity classification capability of the matched-filter method using data obtained from a Kinetisense tri-axis accelerometer sensor.
We have shown that real-time processing on a low-powered micro-controller can be achieved with timing results obtained from the MSP432 microcontroller.
Timing results have demonstrated that radix 2 time-window lengths and frequency values result in faster processing times as expected given that the FFTs account for a significant amount of the processing time.
We increased our throughput with the use of data-compression techniques, namely decimation and dimensionality reduction, which reduced our computational requirements.
The references used in the matched-filter are obtained from the training module where a training set is provided by the user through some specified activity and the best representative motion signature of the individual is extracted through the use of an instance-based learning algorithm.

%%%%%%%%%%%%%%
% References %
%%%%%%%%%%%%%%
\bibliographystyle{plain}
\bibliography{reference}

\end{multicols}

\end{document}
