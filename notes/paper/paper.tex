\documentclass[journal]{IEEEtran}
\usepackage{blindtext}
\usepackage{graphicx}
\usepackage[english]{babel}
\usepackage{pinyin}
\usepackage{natbib}
%
\begin{document}
%
% paper title
\title{Classifying Activities Using Body-Worn Accelerometers for Real-Time Application}
%
\author{Craig~Euler, C.T. Lin, Melissa Flores, et al.}
%
% make the title area
\maketitle
%
\begin{abstract}
Body worn sensors have been used in the market for many years now. Most of which are used specifically for activity monitoring or fitness. In this paper, we present a method for real-time activity classification, from accelerometers worn by the user, by using the matched-filter method. We also discuss the methods used to improve computational efficiency, and the unsupervised learning method for training the device to recognize motion patterns provided by the user.
\end{abstract}
%
\begin{IEEEkeywords}
IEEEtran, journal, \LaTeX, paper, template.
\end{IEEEkeywords}
\IEEEpeerreviewmaketitle
%
\section{Introduction}
Body worn sensors have been used in the market for many years now. Most of which are used specifically for activity monitoring or fitness. While pedometers are common and effective devices used, not many actively identify the activity of the individual for real-time processing. In this paper, we developed a method to identify the individual’s activity in real-time and feed that back to the person or device for further analysis. Having an a priori knowledge of the activity the individual is performing is useful for many current fitness algorithms. These devices (Fit-Bit, Apple watch, Moov, Jawbone, etc.) usually have the individual input the activity they are performing.
%
\section{System Hardware}
The sensor used for this analysis is a three-axis accelerometer unit from Kinetisense. The unit’s acceleration range is -5g to +5g with a sampling rate of 128Hz. Samples of walking, sitting, running, and bicycling have been recorded with the device and used for the analysis in this paper.
%
\subsection{Activity Identification}
The matched-filter method is commonly used for extracting a signal out of noisy data. We employ this method for identifying a user’s activity from data generated by body-worn accelerometers. Because the matched-filter method requires use of an existing reference template to identify the desired signal, we must develop our template from a training set. We will discuss how we develop our set of templates for use in our matched-filter.
%
\subsection{Dimensionality Reduction}
e manage to reduce our computational resources and remove our dependence on sensor orientation at the same time through a process of dimensionality reduction. We base our assumption that over a short period of time a user’s limb movement is constrained mostly to a two-dimensional plane. By identifying the plane of motion, we then project the acceleration data onto this plane and re-define our x and y axis accordingly. Because most common activities are mostly confined to two dimensions, this will improve our signal identification.
\cite{bgk}
%
\section{Training the Module}
Each person has a unique physical signature for each physical activity they perform. For our application, we develop a reference signature for our matched filter directly from the person’s motion signature. We do this by having the individual perform the specific activity over a specified amount of time and select the sub-interval of time that we find best represents the user's motion signature. For a given activity, we attempt to find the representative periodic signal s of our individual’s activity to be our template. We assume there is a close enough representative signal s’ = s + e’ to be taken over some pre-set finite length interval I present in our training set X. Because the activities we are interested in classifying are periodic and range closely around 1.0 seconds we choose an interval I near 1.0 seconds. We divide our training set X into N sub intervals ${s_1, s_2, …, s_N}$ and we test each one against all the other ones.
%
\section{Conclusion}
conclusion text here
%
\appendices
%
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi
%
\bibliographystyle{plain}
\bibliography{reference}
\end{document}


